# services/llm_extractor.py
import os
from dotenv import load_dotenv

load_dotenv(".env")

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # openai SDK æœ‰é—®é¢˜æ—¶ç›´æŽ¥èµ° fallback


ASSISTANT_STYLE = os.getenv("ASSISTANT_STYLE", "structured").lower()
# å¯é€‰:
# - "structured" -> emoji + åˆ†åŒºæ ‡é¢˜
# - "minimal"    -> ç®€æ´çº¯æ–‡æœ¬ (æš‚æ—¶æˆ‘ä»¬ä¸»è¦ç”¨ structured)


ACTION_KEYWORDS = [
    "please",
    "rsvp",
    "reply",
    "respond",
    "sign",
    "complete",
    "fill out",
    "submit",
    "bring",
    "pay",
    "schedule",
    "register",
    "book",
]


def _detect_simple_action_item(body: str) -> str:
    """éžå¸¸ç®€å•çš„å…³é”®è¯æ£€æµ‹ï¼Œç”¨äºŽ fallback æ¨¡å¼ä¸‹ç»™ä¸€ç‚¹ hintã€‚"""
    text = (body or "").lower()

    hits = [kw for kw in ACTION_KEYWORDS if kw in text]

    if not hits:
        return "None detected (simple fallback summary)."

    # åªè¦å‘½ä¸­å°±ç»™ä¸€ä¸ªå®½æ³›çš„ action æç¤º
    pretty_hits = [f"â€œ{kw}â€" for kw in hits[:3]]
    hit_str = ", ".join(pretty_hits)
    return f"Looks like thereâ€™s something you may need to do â€” this email mentions {hit_str}."


def _fallback_summary(subject: str, body: str, style: str = "structured") -> str:
    """å½“æ²¡æœ‰ key æˆ– OpenAI è°ƒç”¨å¤±è´¥æ—¶ï¼Œç”¨ä¸€ä¸ªç®€å•ä½†ç»“æž„åŒ–çš„æ‘˜è¦ã€‚"""
    snippet = (body or "").strip().replace("\n", " ")
    snippet = snippet[:200] + ("..." if len(snippet) > 200 else "")
    action_line = _detect_simple_action_item(body or "")

    if style == "minimal":
        # ç®€æ´ç‰ˆ
        return (
            f"Subject: {subject or '(no subject)'}\n\n"
            f"Key info: {snippet or 'No content.'}"
        )

    # é»˜è®¤ï¼šå¸¦ emoji çš„ç»“æž„åŒ–ç‰ˆæœ¬
    return (
        "ðŸ“‹ Summary\n"
        f"- {snippet or 'No content.'}\n\n"
        "ðŸ•’ Key details\n"
        f"- Subject: {subject or '(no subject)'}\n\n"
        "âœ… Action items\n"
        f"- {action_line}\n\n"
        "ðŸ“… Calendar\n"
        "- No explicit date/time parsing in fallback."
    )


def summarize_email(subject: str, body: str) -> str:
    """
    ç”¨ OpenAI åšæ‘˜è¦ï¼š
    - æœ‰ OPENAI_API_KEY ä¸” SDK æ­£å¸¸ -> è°ƒ GPTï¼Œè¿”å›žç»“æž„åŒ–æ‘˜è¦
    - æ²¡ key / SDK æˆ–è°ƒç”¨å¤±è´¥ -> èµ° fallbackï¼Œä¹Ÿç”¨ç»Ÿä¸€é£Žæ ¼
    """
    api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        print("[LLM] No OPENAI_API_KEY found, using fallback summary.")
        return _fallback_summary(subject, body, ASSISTANT_STYLE)

    if OpenAI is None:
        print("[LLM] openai SDK not available, using fallback summary.")
        return _fallback_summary(subject, body, ASSISTANT_STYLE)

    try:
        print("[LLM] Using OpenAI GPT for summarization.")

        client = OpenAI(api_key=api_key)

        if ASSISTANT_STYLE == "minimal":
            system_prompt = (
                "You are an assistant that summarizes emails for a very busy parent.\n"
                "Respond in plain text with this format:\n\n"
                "Subject: <subject>\n\n"
                "Key info: <1â€“3 short sentences focusing on dates, times, locations, and actions.>\n"
                "Keep it under 100 words. Do NOT invent information.\n"
            )
        else:
            # é»˜è®¤ structured + emoji é£Žæ ¼
            system_prompt = (
                "You are an assistant that summarizes emails for a very busy parent.\n"
                "You MUST respond in this exact format (in English):\n\n"
                "ðŸ“‹ Summary\n"
                "- ...\n\n"
                "ðŸ•’ Key details\n"
                "- ...\n"
                "- ...\n\n"
                "âœ… Action items\n"
                "- ... (or 'None')\n\n"
                "ðŸ“… Calendar\n"
                "- ... (describe any event that should go on a calendar, or 'None').\n\n"
                "Rules:\n"
                "- Keep it under 120 words in total.\n"
                "- Focus on dates, times, locations, and what the parent needs to do.\n"
                "- Do NOT invent information that is not in the email.\n"
            )

        user_content = f"Subject: {subject}\n\nBody:\n{body}"

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content},
            ],
            temperature=0.2,
            max_tokens=260,
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        print("[LLM] Error calling OpenAI, falling back to simple summary:", repr(e))
        return _fallback_summary(subject, body, ASSISTANT_STYLE)